{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete. Saved to 'heart_data_converted.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('../data/heart.csv')  # Replace 'heart_data.csv' with your actual file name\n",
    "\n",
    "# Rename the 'thal' column to 'Thalassemia'\n",
    "df.rename(columns={'cp': 'ChestPainType'}, inplace=True)\n",
    "df.rename(columns={'trestbps': 'RestingBP'}, inplace=True)\n",
    "df.rename(columns={'chol': 'Cholesterol'}, inplace=True)\n",
    "df.rename(columns={'fbs': 'FastingBS'}, inplace=True)\n",
    "df.rename(columns={'restecg': 'RestingECG'}, inplace=True)\n",
    "df.rename(columns={'mhra': 'MaxHR'}, inplace=True)\n",
    "df.rename(columns={'exang': 'ExerciseAngina'}, inplace=True)\n",
    "df.rename(columns={'slope': 'ST_Slope'}, inplace=True)\n",
    "df.rename(columns={'ca': 'coronaryArtery'}, inplace=True)\n",
    "df.rename(columns={'thal': 'Thalassemia'}, inplace=True)\n",
    "\n",
    "# Convert the 'sex' column: 1 -> 'Male', 0 -> 'Female'\n",
    "df['sex'] = df['sex'].map({1: 'Male', 0: 'Female'})\n",
    "\n",
    "# Convert the 'fbs' column: 1 -> 'Greater than 120 mg/dl', 0 -> 'Less than 120 mg/dl'\n",
    "df['FastingBS'] = df['FastingBS'].map({1: '121', 0: '120'}) #ok\n",
    "df['RestingECG'] = df['RestingECG'].map({0: 'Normal', 1: 'ST-T wave abnormality', 2: 'Left ventricular hypertrophy'}) #ok\n",
    "df['ST_Slope'] = df['ST_Slope'].map({0: 'Up-sloping', 1: 'Flat', 2: 'Down-sloping'})#ok\n",
    "df['Thalassemia'] = df['Thalassemia'].map({1: 'Normal', 2: 'Fixed Defect', 3: 'Reversible Defect'}) #ok-ok\n",
    "df['ChestPainType'] = df['ChestPainType'].map({0: 'Typical Angina', 1: 'Atypical Angina', 2: 'Non-Anginal Pain', 3: 'Asymptomatic'})#ok\n",
    "\n",
    "# Save the updated DataFrame back to a new CSV file\n",
    "df.to_csv('heart_data_converted.csv', index=False)\n",
    "\n",
    "print(\"Conversion complete. Saved to 'heart_data_converted.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sex': LabelEncoder(), 'ChestPainType': LabelEncoder(), 'RestingECG': LabelEncoder(), 'ST_Slope': LabelEncoder(), 'Thalassemia': LabelEncoder()}\n",
      "   age  RestingBP  Cholesterol  FastingBS  MaxHR  ExerciseAngina  oldpeak  \\\n",
      "0   52        125          212        120    168               0      1.0   \n",
      "1   53        140          203        121    155               1      3.1   \n",
      "\n",
      "   coronaryArtery  target  sex  ChestPainType  RestingECG  ST_Slope  \\\n",
      "0               2       0    1              3           2         0   \n",
      "1               0       0    1              3           1         2   \n",
      "\n",
      "   Thalassemia  \n",
      "0            2  \n",
      "1            2  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('../notebooks/heart_data_converted.csv')\n",
    "\n",
    "# Select categorical columns\n",
    "df_cat = df.select_dtypes(include=['object'])\n",
    "# print(df_cat)\n",
    "# Initialize LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Initialize an empty DataFrame to store encoded columns\n",
    "df_encoded = pd.DataFrame()\n",
    "label_encoders = {}\n",
    "\n",
    "# Apply LabelEncoder to each categorical column\n",
    "for col in df_cat.columns:\n",
    "    le = LabelEncoder()\n",
    "    df_encoded[col] = le.fit_transform(df_cat[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# print(label_encoders)\n",
    "with open('../encoders/label_encoders.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoders, f)\n",
    "print(label_encoders)\n",
    "# Convert encoded columns to one-hot encoding\n",
    "# df_encoded = pd.get_dummies(df_encoded, drop_first=True)\n",
    "\n",
    "# Drop the original categorical columns from the original DataFrame\n",
    "df = df.drop(columns=df_cat.columns)\n",
    "\n",
    "# Concatenate the one-hot encoded columns with the original DataFrame (excluding categorical columns)\n",
    "df = pd.concat([df, df_encoded], axis=1)\n",
    "\n",
    "print(df.head(2))\n",
    "df.to_csv('../data/encoded.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     age  RestingBP  Cholesterol  FastingBS  MaxHR  ExerciseAngina  oldpeak  \\\n",
      "527   62        124          209        120    163               0      0.0   \n",
      "359   53        128          216        120    115               0      0.0   \n",
      "447   55        160          289        120    145               1      0.8   \n",
      "31    50        120          244        120    162               0      1.1   \n",
      "621   48        130          256        121    150               1      0.0   \n",
      "\n",
      "     coronaryArtery  sex  ChestPainType  RestingECG  ST_Slope  Thalassemia  \n",
      "527               0    0              3           2         0            0  \n",
      "359               0    0              2           1         0            3  \n",
      "447               1    1              3           1         1            2  \n",
      "31                0    0              1           2         0            0  \n",
      "621               2    1              3           1         0            2  \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       159\n",
      "           1       1.00      0.98      0.99       149\n",
      "\n",
      "    accuracy                           0.99       308\n",
      "   macro avg       0.99      0.99      0.99       308\n",
      "weighted avg       0.99      0.99      0.99       308\n",
      "\n",
      "Model and encoders saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "# Load and preprocess the data\n",
    "df = pd.read_csv('../data/encoded.csv')\n",
    "\n",
    "# Print initial data and columns for verification\n",
    "# print(\"Initial Data:\")\n",
    "# print(df.head())\n",
    "# print(\"Columns:\", df.columns)\n",
    "\n",
    "# Prepare features and target variable\n",
    "X = df.drop(columns=['target'])\n",
    "y = df['target']\n",
    "\n",
    "# print(y)\n",
    "\n",
    "# # Identify categorical columns\n",
    "# categorical_columns = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "# print(\"Categorical Columns:\", categorical_columns)\n",
    "\n",
    "# # Apply LabelEncoder to each categorical column\n",
    "# label_encoders = {}\n",
    "# for col in categorical_columns:\n",
    "#     le = LabelEncoder()\n",
    "#     le.fit(X[col])\n",
    "#     label_encoders[col] = le\n",
    "\n",
    "#     # Transform the column in X with the encoder\n",
    "#     X[col] = le.transform(X[col])\n",
    "#     print(f\"Encoded column '{col}' with classes: {le.classes_}\")\n",
    "\n",
    "# Save the LabelEncoders\n",
    "# with open('label_encoders.pkl', 'wb') as f:\n",
    "#     pickle.dump(label_encoders, f)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(X_test.iloc[0:5])\n",
    "# Save the training set\n",
    "# with open('x_train.pkl', 'wb') as f:\n",
    "#     pickle.dump(X_train, f)\n",
    "\n",
    "# Initialize and train the RandomForest model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "# print(X_train)\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "# print(y_test)\n",
    "# print(y_pred)\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(model, '../models/random_forest_model.pkl')\n",
    "\n",
    "print(\"Model and encoders saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       132\n",
      "           1       1.00      0.98      0.99       125\n",
      "\n",
      "    accuracy                           0.99       257\n",
      "   macro avg       0.99      0.99      0.99       257\n",
      "weighted avg       0.99      0.99      0.99       257\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       122\n",
      "           1       1.00      1.00      1.00       134\n",
      "\n",
      "    accuracy                           1.00       256\n",
      "   macro avg       1.00      1.00      1.00       256\n",
      "weighted avg       1.00      1.00      1.00       256\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       122\n",
      "           1       1.00      1.00      1.00       134\n",
      "\n",
      "    accuracy                           1.00       256\n",
      "   macro avg       1.00      1.00      1.00       256\n",
      "weighted avg       1.00      1.00      1.00       256\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       123\n",
      "           1       1.00      1.00      1.00       133\n",
      "\n",
      "    accuracy                           1.00       256\n",
      "   macro avg       1.00      1.00      1.00       256\n",
      "weighted avg       1.00      1.00      1.00       256\n",
      "\n",
      "Average Accuracy across 4 folds: 1.00\n",
      "Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "# Load and preprocess the data\n",
    "df = pd.read_csv('../data/encoded.csv')\n",
    "\n",
    "# Prepare features and target variable\n",
    "X = df.drop(columns=['target'])\n",
    "y = df['target']\n",
    "\n",
    "# Initialize the K-Fold cross-validator\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "# Store results\n",
    "accuracy_scores = []\n",
    "\n",
    "# K-Fold Cross Validation\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Initialize and train the RandomForest model\n",
    "    model = RandomForestClassifier(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions and evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = (y_pred == y_test).mean()  # Calculate accuracy\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print average accuracy across folds\n",
    "average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
    "print(f\"Average Accuracy across {kf.n_splits} folds: {average_accuracy:.2f}\")\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(model, '../models/random_forest_model.pkl')\n",
    "print(\"Model saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       132\n",
      "           1       1.00      0.98      0.99       125\n",
      "\n",
      "    accuracy                           0.99       257\n",
      "   macro avg       0.99      0.99      0.99       257\n",
      "weighted avg       0.99      0.99      0.99       257\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       122\n",
      "           1       1.00      1.00      1.00       134\n",
      "\n",
      "    accuracy                           1.00       256\n",
      "   macro avg       1.00      1.00      1.00       256\n",
      "weighted avg       1.00      1.00      1.00       256\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       122\n",
      "           1       1.00      1.00      1.00       134\n",
      "\n",
      "    accuracy                           1.00       256\n",
      "   macro avg       1.00      1.00      1.00       256\n",
      "weighted avg       1.00      1.00      1.00       256\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       123\n",
      "           1       1.00      1.00      1.00       133\n",
      "\n",
      "    accuracy                           1.00       256\n",
      "   macro avg       1.00      1.00      1.00       256\n",
      "weighted avg       1.00      1.00      1.00       256\n",
      "\n",
      "Average Accuracy across 4 folds: 1.00\n",
      "Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "import jellyfish\n",
    "import numpy as np\n",
    "\n",
    "# Load and preprocess the data\n",
    "df = pd.read_csv('../data/encoded.csv')\n",
    "\n",
    "# Example function to compute similarity scores using Jellyfish\n",
    "def compute_similarity(column):\n",
    "    # Example reference string to compare against, adjust as needed\n",
    "    reference = 'typical angina'\n",
    "    return column.apply(lambda x: 1 - (jellyfish.levenshtein_distance(x, reference) / max(len(x), len(reference))))\n",
    "\n",
    "# Example preprocessing of a categorical column (replace 'chest_pain_type' with actual column name)\n",
    "# df['chest_pain_type'] = compute_similarity(df['chest_pain_type'])\n",
    "\n",
    "# Prepare features and target variable\n",
    "X = df.drop(columns=['target'])\n",
    "y = df['target']\n",
    "\n",
    "# Initialize the K-Fold cross-validator\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "# Store results\n",
    "accuracy_scores = []\n",
    "\n",
    "# K-Fold Cross Validation\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Initialize and train the RandomForest model\n",
    "    model = RandomForestClassifier(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions and evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = (y_pred == y_test).mean()  # Calculate accuracy\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print average accuracy across folds\n",
    "average_accuracy = np.mean(accuracy_scores)\n",
    "print(f\"Average Accuracy across {kf.n_splits} folds: {average_accuracy:.2f}\")\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(model, '../models/random_forest_model.pkl')\n",
    "print(\"Model saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jellyfish\n",
      "  Downloading jellyfish-1.1.0-cp311-none-win_amd64.whl.metadata (2.6 kB)\n",
      "Downloading jellyfish-1.1.0-cp311-none-win_amd64.whl (207 kB)\n",
      "   ---------------------------------------- 0.0/207.3 kB ? eta -:--:--\n",
      "   ------- -------------------------------- 41.0/207.3 kB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  204.8/207.3 kB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 207.3/207.3 kB 2.5 MB/s eta 0:00:00\n",
      "Installing collected packages: jellyfish\n",
      "Successfully installed jellyfish-1.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install jellyfish"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
